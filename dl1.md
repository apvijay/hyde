---
layout: page
title: Paper Notes - Deep Learning I
mathjax: true
---
Paper Notes - Deep Learning I

#Learning to deblur
Schuler
[Paper]()
Oct 7, 2016

## Network architecture
[Stage-1] = Input--[CNN]--[Kernel Estimation]--[Image Estimation]--Output
- Input: Blurred image
- CNN output: Two sets of feature images which still follow the convolution relation similar to input and output

- KE input: above
- KE output: kernel PSF

- IE input: above, Input image
- IE output: deblurred image

- Output: Deblurred image

[Other stages] = Input--[CNN]--[Kernel Estimation]--[Image Estimation]--Output
- Input: Previous stage deblurred image, blurred image


#A Neural Approach to Blind Motion Deblurring
Ayan Chakrabarti, 2016
[Paper](http://arxiv.org/abs/1603.04771)
Oct 3, 2016

- The output of the network is the Fourier coefficient tensor of a deconvolution filter that can be applied to the input patch to create a sharp patch.
- The image is divided into overlapping patches and each patch is processed independently by the network.

## Network architecture
- Input: A set of Fourier coefficients of the input image patch  (and not the image intensities) of size 289-scalar tensor
- Output: A set of Fourier cofficients corresponding to the deconvolution filter of size 4096-scalar tensor

The input tensor is a concatenation of four bands of frequencies different sampled, L, B1, B2, and H. The L is the low pass filter, Bs are the band pass filters, and H is high pass. The higher frequencies are DFTd from a small size image and the lower are from larger size patch. 

### Frequency bands
- L band uses the full patch size is \\(65 \times 65\\) and there are \\(40\\) complex coefficients and one DC coefficient. The total scalars is \\(81\\). The DFT indices retained are \\(max|z| < 4\\).
- B1, B2, and H bands use three patch sizes \\(65 \times 65\\), \\(33 \times 33\\), and \\(17 \times 17\\), respectively. There are \\(104\\) complex coefficients, and hence, the total scalars is \\(208\\). The DFT indices retained are \\(4 < max|z| < 8\\).
- The total input size is therefore \\(289\\).

### The error
Even though the network output is the complex deconvolution filter Fourier cofficient tensor, the backpropagation starts from the MSE of the image intensities.

\\[MSE(x\_P,\hat{x}\_P) = \frac{1}{|P|} \sum\_{n \in P} (\hat{x}\_P[n] - x\_P[n])^2\\]

The MSE in \\(x\\) domain is backpropagated via IDFT block \\(X\\), and then to the network output \\(G\\) via division by \\(Y\\).

## Training
- Sharp image patches from Pascal VOC 2012 are synthetically blurred and noised by 1% std Gaussian.
- Motion kernels are generated by fitting a spline through randomly picked six points in grid sizes of \\(8 \times 8\\), \\(16 \times 16\\) , and \\(24 \times 24\\).
- The kernel's centre of mass is at the centre of the window.
- The training and validation patches count: 520,000 and 3000. They use 100,000 and 3,000 motion kernels, respectively.
- SGD with momentum 0.9. First 800k iterations have learning rate of 32 and then divided by \\(\sqrt{2}\\) after every 100k iterations.
- Time taken : 3 days in an NVIDIA Titan X GPU

## Deblurring
- The process is convoluted. For each patch of the blurred image, a deconvolution filter is estimated using the NN and a corresponding clean patch is estimated. 
- Each pixel of the blurred image is replaced by the corresponding pixel in a weighted combination of estimated clean patches containing that pixel. Thus, we arrive at an estimated clean image. 
- But this is not used as the final output. This is used as an initial estimate of the latent image and a global blur kernel is estimated using the blurred and the estimated latent images. 
- And then again, the final latent image is estimated used a state-of-the-art non-blind deconvolution of EPLL using the estimated kernel and the given blurred image.

