---
layout: page
title: Paper Notes - Deep Learning I
mathjax: true
---
Paper Notes - Deep Learning I

#A Neural Approach to Blind Motion Deblurring
Ayan Chakrabarti, 2016
[Paper](http://arxiv.org/abs/1603.04771)

- The output of the network is the Fourier coefficient tensor of a deconvolution filter that can be applied to the input patch to create a sharp patch.
- The image is divided into overlapping patches and each patch is processed independently by the network.

## Network architecture
- Input: A set of Fourier coefficients of the input image patch  (and not the image intensities) of size 289-scalar tensor
- Output: A set of Fourier cofficients corresponding to the deconvolution filter of size 4096-scalar tensor

The input tensor is a concatenation of four bands of frequencies different sampled, L, B1, B2, and H. The L is the low pass filter, Bs are the band pass filters, and H is high pass. The higher frequencies are DFTd from a small size image and the lower are from larger size patch. 

### Frequency bands
- L band uses the full patch size is \\(65 \times 65\\) and there are \\(40\\) complex coefficients and one DC coefficient. The total scalars is \\(81\\). The DFT indices retained are \\(max|z| < 4\\).
- B1, B2, and H bands use three patch sizes \\(65 \times 65\\), \\(33 \times 33\\), and \\(17 \times 17\\), respectively. There are \\(104\\) complex coefficients, and hence, the total scalars is \\(208\\). The DFT indices retained are \\(4 < max|z| < 8\\).
- The total input size is therefore \\(289\\).

### The error
Even though the network output is the complex deconvolution filter Fourier cofficient tensor, the backpropagation starts from the MSE of the image intensities.
$$MSE(x_P,\hat{x}_P) = \frac{1}{|P|} \sum_{n \in P} (\hat{x}_P[n] - x_P[n])^2$$ 
The MSE in \\(x\\) domain is backpropagated via IDFT block \\(X\\), and then to the network output \\(G\\) via division by \\(Y\\).

## Training
- Sharp image patches from Pascal VOC 2012 are synthetically blurred and noised by 1% std Gaussian.
- Motion kernels are generated by fitting a spline through randomly picked six points in grid sizes of \\(8 \times 8\\), \\(16 \times 16\\) , and \\(24 \times 24\\).
- The kernel's centre of mass is at the centre of the window.
- The training and validation patches count: 520,000 and 3000. They use 100,000 and 3,000 motion kernels, respectively.
- SGD with momentum 0.9. First 800k iterations have learning rate of 32 and then divided by \\(\sqrt{2}\\) after every 100k iterations.
- Time taken : 3 days in an NVIDIA Titan X GPU